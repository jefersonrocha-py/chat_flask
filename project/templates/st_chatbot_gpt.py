import os
import logging
from dotenv import load_dotenv
import streamlit as st
from langchain_community.chat_models import ChatOllama
from langchain_core.prompts import ChatPromptTemplate
import json
import requests

# Configura√ß√£o de logging
logging.basicConfig(
    filename="chatbot_errors.log",
    level=logging.ERROR,
    format="%(asctime)s - %(levelname)s - %(message)s"
)

# Fun√ß√£o para exibir mensagens de erro amig√°veis
def show_error(message):
    st.error(f"üòï Oops! Algo deu errado: {message}")
    logging.error(message)

# Carregar vari√°veis de ambiente
try:
    load_dotenv()
except Exception as e:
    show_error(f"N√£o foi poss√≠vel carregar vari√°veis de ambiente: {e}")

# Configura√ß√µes do Ollama
OLLAMA_SERVER_URL = "http://localhost:11434"

# Verificar conex√£o com o servidor backend
def check_backend_connection():
    OLLAMA_SERVER_URL = "http://localhost:11434"
    try:
        response = requests.get(OLLAMA_SERVER_URL, timeout=5)
        if response.status_code == 200:
            return True
        else:
            st.error(f"Erro ao conectar ao servidor backend: Status Code {response.status_code}")
    except requests.exceptions.Timeout:
        st.error(f"Timeout ao tentar conectar ao servidor backend em {OLLAMA_SERVER_URL}.")
    except Exception as e:
        st.error(f"Erro ao conectar ao servidor backend: {e}")
    return False

# Executa a verifica√ß√£o da conex√£o
backend_connected = check_backend_connection()
if not backend_connected:
    st.warning("‚ö†Ô∏è O servidor backend n√£o est√° dispon√≠vel. Algumas funcionalidades podem estar limitadas.")

# Configurar o Ollama como provedor de chat
CHAT_MODEL = "llama3.2:latest"
try:
    chat_model = ChatOllama(base_url=OLLAMA_SERVER_URL, model=CHAT_MODEL)
except Exception as e:
    show_error(f"Erro ao configurar o modelo de chat: {e}")
    st.stop()

# CSS customizado para estiliza√ß√£o
st.markdown(
    """
    <style>
    .css-18e3th9 { padding-top: 1rem; }
    .css-1d391kg { padding: 0; }
    .chat-title { font-size: 32px; font-weight: bold; text-align: center; margin-bottom: 10px; color: #4CAF50; }
    .sidebar-footer { position: fixed; bottom: 0; width: 250px; background-color: transparent; padding: 10px 0; text-align: center; box-shadow: none; }
    .avatar-container { display: flex; align-items: center; justify-content: center; margin-bottom: 20px; }
    .avatar-initial { width: 60px; height: 60px; border-radius: 50%; background-color: #4CAF50; color: white; font-size: 24px; font-weight: bold; display: flex; align-items: center; justify-content: center; margin-right: 0.5rem; }
    .back-button { background-color: #2196F3; color: white; padding: 0.6em 1em; border: none; border-radius: 20px; cursor: pointer; text-decoration: none; font-size: 16px; font-weight: bold; box-shadow: none; outline: none; transition: background-color 0.3s ease; }
    [data-testid="stSidebar"] .back-button { background-color: #2196F3; }
    [data-testid="stSidebar"][class*="dark"] .back-button { background-color: #1E88E5; }
    </style>
    """,
    unsafe_allow_html=True,
)

# Obter o username dos par√¢metros da URL
query_params = st.query_params
user_logged = query_params.get("username", ["Usu√°rio"])[0]

# Fun√ß√£o para gerar t√≠tulo autom√°tico da conversa
def generate_conversation_title(messages):
    try:
        if messages:
            content = messages[0]["content"]
            return content[:30] + "..." if len(content) > 30 else content
        return "Nova Conversa"
    except Exception as e:
        show_error(f"Erro ao gerar t√≠tulo da conversa: {e}")
        return "Nova Conversa"

# Fun√ß√£o para salvar hist√≥rico em JSON
def save_history():
    try:
        with open("chat_history.json", "w") as f:
            json.dump({
                "conversation_history": st.session_state.conversation_history,
                "conversation_titles": st.session_state.conversation_titles
            }, f)
    except Exception as e:
        show_error(f"Erro ao salvar hist√≥rico: {e}")

def chatbot_gpt_page():
    st.markdown(
        """
        <div class="chat-title">FlowMind AI ü§ñ</div>
        """,
        unsafe_allow_html=True
    )

    with st.sidebar:
        initial = user_logged[0].upper() if user_logged else "U"
        st.markdown(
            f"""
            <div class="avatar-container">
                <div class="avatar-initial">{initial}</div>
            </div>
            """,
            unsafe_allow_html=True
        )

        st.header("üìú Hist√≥rico de Conversas")
        if "conversation_history" not in st.session_state:
            st.session_state.conversation_history = []
        if "conversation_titles" not in st.session_state:
            st.session_state.conversation_titles = []
        if "current_conversation_index" not in st.session_state:
            st.session_state.current_conversation_index = None

        try:
            for i, history in enumerate(st.session_state.conversation_history):
                default_title = f"Conversa {i + 1}"
                title = st.session_state.conversation_titles[i] if i < len(st.session_state.conversation_titles) else default_title
                new_title = st.text_input(f"T√≠tulo da conversa {i + 1}", value=title, key=f"title_{i}_input")
                if new_title != title:
                    if i < len(st.session_state.conversation_titles):
                        st.session_state.conversation_titles[i] = new_title
                    else:
                        st.session_state.conversation_titles.append(new_title)
                if st.button(f"Selecionar {title}", key=f"select_{i}"):
                    st.session_state.current_conversation_index = i
                    st.session_state.current_messages = history.copy()
            if st.button("‚ú® Iniciar novo Chat", key="new_chat", help="Clique para come√ßar uma nova conversa"):
                st.session_state.current_messages = []
                st.session_state.current_conversation_index = len(st.session_state.conversation_history)
                st.session_state.conversation_titles.append("Nova Conversa")
                st.success("Nova conversa iniciada!")
        except Exception as e:
            show_error(f"Erro ao gerenciar hist√≥rico de conversas: {e}")

        FLASK_ROUTE = "http://localhost:5000/mode_selection"
        st.markdown(
            f"""
            <div class="sidebar-footer">
                <a href="{FLASK_ROUTE}" target="_self" style="text-decoration: none;">
                    <button class="back-button">üîô Voltar</button>
                </a>
            </div>
            """,
            unsafe_allow_html=True
        )

    # Template do prompt
    conversation_prompt = ChatPromptTemplate.from_template(
        """
        Voc√™ √© um assistente virtual especializado. 
        Forne√ßa respostas claras, concisas e √∫teis com base no contexto da conversa.
        Mensagens anteriores:
        {history}
        Nova pergunta do usu√°rio:
        {user_input}
        """
    )

    if "current_messages" not in st.session_state:
        st.session_state.current_messages = []

    try:
        for message in st.session_state.current_messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"], unsafe_allow_html=True)
    except Exception as e:
        show_error(f"Erro ao exibir mensagens: {e}")

    # Entrada do usu√°rio
    if user_input := st.chat_input("Digite sua mensagem aqui:"):
        st.session_state.current_messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)
        try:
            previous_messages = [
                {"role": msg["role"], "content": msg["content"]}
                for msg in st.session_state.current_messages
            ]
            prompt = conversation_prompt.format(
                history="\n".join(f"{msg['role']}: {msg['content']}" for msg in previous_messages),
                user_input=user_input
            )
            with st.spinner("Gerando resposta..."):
                response_stream = chat_model.stream(prompt)
                full_response = ""
                response_container = st.chat_message("assistant")
                response_text = response_container.empty()
                for partial_response in response_stream:
                    content = partial_response.content
                    full_response += content
                    response_text.markdown(full_response + "‚ñå", unsafe_allow_html=True)
                st.session_state.current_messages.append({"role": "assistant", "content": full_response})
                save_history()
        except Exception as e:
            show_error(f"Erro ao gerar resposta: {e}")

    # Salva a conversa no hist√≥rico
    try:
        if st.session_state.current_messages:
            idx = st.session_state.current_conversation_index
            if idx is None or idx >= len(st.session_state.conversation_history):
                st.session_state.conversation_history.append(st.session_state.current_messages.copy())
                st.session_state.conversation_titles.append(generate_conversation_title(st.session_state.current_messages))
                st.session_state.current_conversation_index = len(st.session_state.conversation_history) - 1
            else:
                st.session_state.conversation_history[idx] = st.session_state.current_messages.copy()
                st.session_state.conversation_titles[idx] = generate_conversation_title(st.session_state.current_messages)
            save_history()
    except Exception as e:
        show_error(f"Erro ao salvar conversa no hist√≥rico: {e}")

# Executa a p√°gina
try:
    chatbot_gpt_page()
except Exception as e:
    show_error(f"Erro cr√≠tico na aplica√ß√£o: {e}")